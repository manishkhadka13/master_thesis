Starting job at Fri Oct 24 15:16:32 CEST 2025
Job ID: 158467
Running on node: ailab-l4-05
Active conda environment: llm
Python path: /ceph/home/student.aau.dk/jx88vo/miniconda3/envs/llm/bin/python
Python version: Python 3.10.18
Loaded 1560 rows from custom_dataset.csv
Processing all 1560 samples...
Error loading model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 74.00 MiB is free. Process 2565539 has 21.77 GiB memory in use. Including non-PyTorch memory, this process has 186.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Job completed at Fri Oct 24 15:20:00 CEST 2025
