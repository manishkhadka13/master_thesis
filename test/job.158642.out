Starting job at Sun Oct 26 11:12:26 CET 2025
Job ID: 158642
Running on node: ailab-l4-03
Active conda environment: llm
Python path: /ceph/home/student.aau.dk/jx88vo/miniconda3/envs/llm/bin/python
Python version: Python 3.10.18
Loaded 1560 rows from custom_dataset.csv
Processing all 1560 samples...
Error loading model: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 22.00 MiB is free. Process 512822 has 11.00 GiB memory in use. Including non-PyTorch memory, this process has 11.00 GiB memory in use. Of the allocated memory 10.77 GiB is allocated by PyTorch, and 51.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Job completed at Sun Oct 26 11:14:31 CET 2025
